25/02/15 10:39:53 INFO CapstoneProjectApp-LOCAL: Spark App is Running...
25/02/15 10:39:53 INFO CapstoneProjectApp-LOCAL: Spark Terminate
25/02/15 10:40:30 INFO CapstoneProjectApp-LOCAL: Spark App is Running...
25/02/15 10:42:17 INFO CapstoneProjectApp-LOCAL: Spark Terminate
25/02/16 17:07:25 INFO CapstoneProjectApp-LOCAL: Spark App is Running...
25/02/16 17:07:25 INFO CapstoneProjectApp-LOCAL: Spark Terminate
25/02/17 17:46:26 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-900e7f74-768b-4e63-baed-0c38fba937a5, Capstone Project is Running..
25/02/17 17:46:26 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 17:46:26 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 17:48:17 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-3727d3c8-bcca-4586-9d95-9b0e89e8d02b, Capstone Project is Running..
25/02/17 17:48:17 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 17:48:17 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 17:51:57 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-72287e99-0b13-45b7-982e-3488a70ab95d, Capstone Project is Running..
25/02/17 17:51:57 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 17:51:57 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 17:55:31 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-17d45dc7-4cdf-4c28-8d50-b2de0c09a26a, Capstone Project is Running..
25/02/17 17:55:31 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 17:55:31 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 17:55:34 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/17 17:55:35 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/17 17:55:35 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/17 17:59:50 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-b9b649d6-3619-4443-ad95-7fd3195cf0d3, Capstone Project is Running..
25/02/17 17:59:50 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 17:59:50 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 17:59:54 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/17 17:59:54 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/17 17:59:54 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/17 18:03:01 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-58dbc296-ae72-4bd0-b750-98f153916782, Capstone Project is Running..
25/02/17 18:03:01 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 18:03:01 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 18:03:05 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/17 18:03:05 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/17 18:03:05 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/17 18:03:29 INFO CapstoneProjectApp-LOCAL: Finished sending data to Kafka
25/02/17 18:03:29 INFO CapstoneProjectApp-LOCAL: Spark Terminate
25/02/17 18:05:56 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-0f34c6bc-9258-4953-8ef9-70fc5fc1b30e, Capstone Project is Running..
25/02/17 18:05:56 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 18:05:56 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 18:06:00 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/17 18:06:00 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/17 18:06:00 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/17 18:21:17 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-fbbfcfc1-154e-4d35-b06c-64c20d3e8326, Capstone Project is Running..
25/02/17 18:21:17 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 18:21:17 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 18:21:23 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/17 18:21:23 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/17 18:21:23 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/17 18:25:06 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-71b9716a-cc9a-4b6b-bf95-a028f5a77cfb, Capstone Project is Running..
25/02/17 18:25:06 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 18:25:06 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 18:25:09 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/17 18:25:09 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/17 18:25:10 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/17 18:25:21 INFO CapstoneProjectApp-LOCAL: Finished sending data to Kafka
25/02/17 18:25:21 INFO CapstoneProjectApp-LOCAL: Spark Terminate
25/02/17 18:26:26 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-a8d6c6d5-fa1e-4aaa-91eb-f16aa4c16051, Capstone Project is Running..
25/02/17 18:26:26 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 18:26:26 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 18:26:29 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/17 18:26:29 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/17 18:26:30 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/17 18:26:30 INFO CapstoneProjectApp-LOCAL: Join Account and Parties
25/02/17 18:26:30 INFO CapstoneProjectApp-LOCAL: Apply Header and create Event
25/02/17 18:26:32 INFO CapstoneProjectApp-LOCAL: Preparing to send data to Kafka
25/02/17 18:27:22 INFO CapstoneProjectApp-LOCAL: Finished sending data to Kafka
25/02/17 18:27:22 INFO CapstoneProjectApp-LOCAL: Spark Terminate
25/02/17 18:37:19 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-e6b8792b-801b-4d68-be13-defd669e724a, Capstone Project is Running..
25/02/17 18:37:19 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 18:37:19 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 18:37:25 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/17 18:37:25 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/17 18:37:25 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/17 18:37:26 INFO CapstoneProjectApp-LOCAL: Join Account and Parties
25/02/17 18:37:26 INFO CapstoneProjectApp-LOCAL: Apply Header and create Event
25/02/17 18:37:26 INFO CapstoneProjectApp-LOCAL: Preparing to send data to Kafka
25/02/17 18:37:45 INFO CapstoneProjectApp-LOCAL: Finished sending data to Kafka
25/02/17 18:37:45 INFO CapstoneProjectApp-LOCAL: Spark Terminate
25/02/17 18:38:45 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-807988c4-3e92-4174-8d05-b4b7ef9ca531, Capstone Project is Running..
25/02/17 18:38:45 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 18:38:45 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 18:38:51 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/17 18:38:51 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/17 18:38:52 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/17 18:38:52 INFO CapstoneProjectApp-LOCAL: Join Account and Parties
25/02/17 18:38:52 INFO CapstoneProjectApp-LOCAL: Apply Header and create Event
25/02/17 18:38:53 INFO CapstoneProjectApp-LOCAL: Preparing to send data to Kafka
25/02/17 18:38:53 ERROR CapstoneProjectApp-LOCAL: Failed to send data to Kafka: An error occurred while calling o410.save.
: java.lang.NoClassDefFoundError: org/apache/kafka/common/serialization/ByteArraySerializer
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$.<init>(KafkaSourceProvider.scala:601)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$.<clinit>(KafkaSourceProvider.scala)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.createRelation(KafkaSourceProvider.scala:180)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:251)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.apache.kafka.common.serialization.ByteArraySerializer
	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)
	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 44 more

25/02/17 18:47:35 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-abf71dc7-9004-4bea-b738-17c921edd6cf, Capstone Project is Running..
25/02/17 18:47:35 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 18:47:35 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 18:47:42 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/17 18:47:42 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/17 18:47:43 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/17 18:47:43 INFO CapstoneProjectApp-LOCAL: Join Account and Parties
25/02/17 18:47:43 INFO CapstoneProjectApp-LOCAL: Apply Header and create Event
25/02/17 18:47:45 INFO CapstoneProjectApp-LOCAL: Preparing to send data to Kafka
25/02/17 18:47:45 ERROR CapstoneProjectApp-LOCAL: Failed to send data to Kafka: An error occurred while calling o418.save.
: java.lang.NoClassDefFoundError: org/apache/kafka/common/serialization/ByteArraySerializer
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$.<init>(KafkaSourceProvider.scala:601)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$.<clinit>(KafkaSourceProvider.scala)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.createRelation(KafkaSourceProvider.scala:180)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:251)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:569)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: java.lang.ClassNotFoundException: org.apache.kafka.common.serialization.ByteArraySerializer
	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:641)
	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:188)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:525)
	... 44 more

25/02/17 18:57:00 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-56799ae0-2f13-4a9e-8d91-70cb3eae09d7, Capstone Project is Running..
25/02/17 18:57:00 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 18:57:00 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 18:57:07 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/17 18:57:07 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/17 18:57:08 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/17 18:57:08 INFO CapstoneProjectApp-LOCAL: Join Account and Parties
25/02/17 18:57:08 INFO CapstoneProjectApp-LOCAL: Apply Header and create Event
25/02/17 18:57:09 INFO CapstoneProjectApp-LOCAL: Preparing to send data to Kafka
25/02/17 18:57:09 ERROR CapstoneProjectApp-LOCAL: Failed to send data to Kafka: An error occurred while calling o418.save.
: java.lang.NoClassDefFoundError: org/apache/kafka/common/serialization/ByteArraySerializer
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$.<init>(KafkaSourceProvider.scala:601)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$.<clinit>(KafkaSourceProvider.scala)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.createRelation(KafkaSourceProvider.scala:180)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:251)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.lang.ClassNotFoundException: org.apache.kafka.common.serialization.ByteArraySerializer
	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)
	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)
	... 44 more

25/02/17 18:58:13 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-6539e834-84d1-46df-b03d-587fe3a87067, Capstone Project is Running..
25/02/17 18:58:13 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 18:58:13 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 18:58:20 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/17 18:58:21 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/17 18:58:21 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/17 18:58:21 INFO CapstoneProjectApp-LOCAL: Join Account and Parties
25/02/17 18:58:21 INFO CapstoneProjectApp-LOCAL: Apply Header and create Event
25/02/17 18:58:22 INFO CapstoneProjectApp-LOCAL: Preparing to send data to Kafka
25/02/17 18:58:23 ERROR CapstoneProjectApp-LOCAL: Failed to send data to Kafka: An error occurred while calling o418.save.
: java.lang.NoClassDefFoundError: org/apache/kafka/common/serialization/ByteArraySerializer
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$.<init>(KafkaSourceProvider.scala:601)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$.<clinit>(KafkaSourceProvider.scala)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.createRelation(KafkaSourceProvider.scala:180)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:251)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.lang.ClassNotFoundException: org.apache.kafka.common.serialization.ByteArraySerializer
	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)
	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)
	... 44 more

25/02/17 19:02:30 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-20051001-d613-4188-96df-35987b490f7c, Capstone Project is Running..
25/02/17 19:02:30 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 19:02:30 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 19:02:37 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/17 19:02:37 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/17 19:02:37 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/17 19:02:38 INFO CapstoneProjectApp-LOCAL: Join Account and Parties
25/02/17 19:02:38 INFO CapstoneProjectApp-LOCAL: Apply Header and create Event
25/02/17 19:02:39 INFO CapstoneProjectApp-LOCAL: Preparing to send data to Kafka
25/02/17 19:02:39 ERROR CapstoneProjectApp-LOCAL: Failed to send data to Kafka: An error occurred while calling o418.save.
: java.lang.NoClassDefFoundError: org/apache/kafka/common/serialization/ByteArraySerializer
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$.<init>(KafkaSourceProvider.scala:601)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$.<clinit>(KafkaSourceProvider.scala)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.createRelation(KafkaSourceProvider.scala:180)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:251)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.lang.ClassNotFoundException: org.apache.kafka.common.serialization.ByteArraySerializer
	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)
	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)
	... 44 more

25/02/17 19:09:49 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-98da074c-eebd-47ad-b65b-c93147a97ff7, Capstone Project is Running..
25/02/17 19:09:49 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 19:09:49 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 19:09:57 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/17 19:09:57 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/17 19:09:57 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/17 19:09:58 INFO CapstoneProjectApp-LOCAL: Join Account and Parties
25/02/17 19:09:58 INFO CapstoneProjectApp-LOCAL: Apply Header and create Event
25/02/17 19:10:02 INFO CapstoneProjectApp-LOCAL: Preparing to send data to Kafka
25/02/17 19:10:02 ERROR CapstoneProjectApp-LOCAL: Failed to send data to Kafka: An error occurred while calling o418.save.
: java.lang.NoClassDefFoundError: org/apache/kafka/common/serialization/ByteArraySerializer
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$.<init>(KafkaSourceProvider.scala:601)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$.<clinit>(KafkaSourceProvider.scala)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.createRelation(KafkaSourceProvider.scala:180)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:251)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.lang.ClassNotFoundException: org.apache.kafka.common.serialization.ByteArraySerializer
	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)
	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)
	... 44 more

25/02/17 19:33:55 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-9cbe902e-5783-497e-9073-168d8d5b148f, Capstone Project is Running..
25/02/17 19:33:55 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 19:33:55 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 19:34:05 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/17 19:34:06 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/17 19:34:06 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/17 19:34:06 INFO CapstoneProjectApp-LOCAL: Join Account and Parties
25/02/17 19:34:06 INFO CapstoneProjectApp-LOCAL: Apply Header and create Event
25/02/17 19:34:08 INFO CapstoneProjectApp-LOCAL: Preparing to send data to Kafka
25/02/17 19:34:08 ERROR CapstoneProjectApp-LOCAL: Failed to send data to Kafka: [WRITE_STREAM_NOT_ALLOWED] `writeStream` can be called only on streaming Dataset/DataFrame.
25/02/17 19:35:43 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-17a0d3d0-5a86-48b1-b6a6-cda8581dd2a3, Capstone Project is Running..
25/02/17 19:35:43 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 19:35:43 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 19:35:53 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/17 19:35:54 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/17 19:35:54 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/17 19:35:55 INFO CapstoneProjectApp-LOCAL: Join Account and Parties
25/02/17 19:35:55 INFO CapstoneProjectApp-LOCAL: Apply Header and create Event
25/02/17 19:35:56 INFO CapstoneProjectApp-LOCAL: Preparing to send data to Kafka
25/02/17 19:35:56 ERROR CapstoneProjectApp-LOCAL: Failed to send data to Kafka: An error occurred while calling o418.save.
: java.lang.NoClassDefFoundError: org/apache/kafka/common/serialization/ByteArraySerializer
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$.<init>(KafkaSourceProvider.scala:601)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$.<clinit>(KafkaSourceProvider.scala)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.createRelation(KafkaSourceProvider.scala:180)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:251)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.lang.ClassNotFoundException: org.apache.kafka.common.serialization.ByteArraySerializer
	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)
	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)
	... 44 more

25/02/17 19:48:06 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-2c6413ff-9ad5-4f69-80bb-db9a01d32139, Capstone Project is Running..
25/02/17 19:48:06 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 19:48:06 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 19:48:13 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/17 19:48:14 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/17 19:48:14 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/17 19:48:15 INFO CapstoneProjectApp-LOCAL: Join Account and Parties
25/02/17 19:48:15 INFO CapstoneProjectApp-LOCAL: Apply Header and create Event
25/02/17 19:48:16 INFO CapstoneProjectApp-LOCAL: Preparing to send data to Kafka
25/02/17 19:48:16 ERROR CapstoneProjectApp-LOCAL: Failed to send data to Kafka: An error occurred while calling o418.save.
: java.lang.NoClassDefFoundError: org/apache/kafka/common/serialization/ByteArraySerializer
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$.<init>(KafkaSourceProvider.scala:601)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider$.<clinit>(KafkaSourceProvider.scala)
	at org.apache.spark.sql.kafka010.KafkaSourceProvider.createRelation(KafkaSourceProvider.scala:180)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:869)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:391)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:364)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:251)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.lang.ClassNotFoundException: org.apache.kafka.common.serialization.ByteArraySerializer
	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)
	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)
	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)
	... 44 more

25/02/17 20:12:42 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-d104e807-de99-4d33-8bef-9fcf04289fea, Capstone Project is Running..
25/02/17 20:12:42 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 20:12:42 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 20:12:51 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/17 20:12:51 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/17 20:12:51 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/17 20:12:52 INFO CapstoneProjectApp-LOCAL: Join Account and Parties
25/02/17 20:12:52 INFO CapstoneProjectApp-LOCAL: Apply Header and create Event
25/02/17 20:12:53 INFO CapstoneProjectApp-LOCAL: Preparing to send data to Kafka
25/02/17 20:13:13 INFO CapstoneProjectApp-LOCAL: Finished sending data to Kafka
25/02/17 20:13:13 INFO CapstoneProjectApp-LOCAL: Spark Terminate
25/02/17 20:15:30 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-53648405-50ea-4b90-948e-16a6b3d4bf5b, Capstone Project is Running..
25/02/17 20:15:30 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/17 20:15:30 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/17 20:15:37 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/17 20:15:38 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/17 20:15:38 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/17 20:15:38 INFO CapstoneProjectApp-LOCAL: Join Account and Parties
25/02/17 20:15:39 INFO CapstoneProjectApp-LOCAL: Apply Header and create Event
25/02/17 20:15:39 INFO CapstoneProjectApp-LOCAL: Preparing to send data to Kafka
25/02/17 20:16:01 INFO CapstoneProjectApp-LOCAL: Finished sending data to Kafka
25/02/17 20:16:01 INFO CapstoneProjectApp-LOCAL: Spark Terminate
25/02/18 10:30:02 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-5403562b-062c-4aa3-bbf2-09e278d2ccf2, Capstone Project is Running..
25/02/18 10:30:02 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/18 10:30:02 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/18 10:30:10 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/18 10:30:11 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/18 10:30:11 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/18 10:30:11 INFO CapstoneProjectApp-LOCAL: Join Account and Parties
25/02/18 10:30:11 INFO CapstoneProjectApp-LOCAL: Apply Header and create Event
25/02/18 10:30:13 INFO CapstoneProjectApp-LOCAL: Preparing to send data to Kafka
25/02/18 10:30:34 INFO CapstoneProjectApp-LOCAL: Finished sending data to Kafka
25/02/18 10:30:34 INFO CapstoneProjectApp-LOCAL: Spark Terminate
25/02/18 12:47:39 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-5dd87dc7-a4e2-439b-a783-a0e27b390071, Capstone Project is Running..
25/02/18 12:47:39 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/18 12:47:39 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/18 12:47:48 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/18 12:47:48 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/18 12:47:48 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/18 12:47:49 INFO CapstoneProjectApp-LOCAL: Join Account and Parties
25/02/18 12:47:49 INFO CapstoneProjectApp-LOCAL: Apply Header and create Event
25/02/18 12:47:51 INFO CapstoneProjectApp-LOCAL: Preparing to send data to Kafka
25/02/18 12:48:12 INFO CapstoneProjectApp-LOCAL: Finished sending data to Kafka
25/02/18 12:48:12 INFO CapstoneProjectApp-LOCAL: Spark Terminate
25/02/19 11:44:46 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-13cbbabf-f558-4fe4-b245-8562eda91d9e, Capstone Project is Running..
25/02/19 11:44:46 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/19 11:44:46 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/19 11:44:54 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/19 11:44:55 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/19 11:44:55 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/19 11:44:55 INFO CapstoneProjectApp-LOCAL: Join Account and Parties
25/02/19 11:44:55 INFO CapstoneProjectApp-LOCAL: Apply Header and create Event
25/02/19 11:44:57 INFO CapstoneProjectApp-LOCAL: Preparing to send data to Kafka
25/02/19 11:45:13 INFO CapstoneProjectApp-LOCAL: Finished sending data to Kafka
25/02/19 11:45:13 INFO CapstoneProjectApp-LOCAL: Spark Terminate
25/02/19 12:11:43 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-430edd0f-c435-48e5-8aaa-ef76d9eca7cd, Capstone Project is Running..
25/02/19 12:11:43 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/19 12:11:43 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/19 12:11:51 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/19 12:11:51 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/19 12:11:51 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/19 12:11:51 INFO CapstoneProjectApp-LOCAL: Join Account and Parties
25/02/19 12:11:52 INFO CapstoneProjectApp-LOCAL: Apply Header and create Event
25/02/19 12:11:54 INFO CapstoneProjectApp-LOCAL: Preparing to send data to Kafka
25/02/19 12:12:11 INFO CapstoneProjectApp-LOCAL: Finished sending data to Kafka
25/02/19 12:12:11 INFO CapstoneProjectApp-LOCAL: Spark Terminate
25/02/19 12:15:05 INFO CapstoneProjectApp-QA: Spark App with ID Capstone-839facbf-ab4e-483d-b553-3f983fde7e2c, Capstone Project is Running..
25/02/19 12:15:05 INFO CapstoneProjectApp-QA: Spark Initialize Data and Variables for Application
25/02/19 12:15:05 INFO CapstoneProjectApp-QA: Spark Reading Account Data..
25/02/19 12:15:17 ERROR CapstoneProjectApp-QA: Failed to read or process account data: [TABLE_OR_VIEW_NOT_FOUND] The table or view `capstone_db_qa`.`accounts` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;
'Project [*]
+- 'UnresolvedRelation [capstone_db_qa, accounts], [], false

25/02/20 09:27:13 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-fef77dec-763e-4162-bce4-596c8c7b9d51, Capstone Project is Running..
25/02/20 09:27:13 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/20 09:27:13 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/20 09:27:23 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/20 09:27:24 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/20 09:27:24 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/20 09:27:25 INFO CapstoneProjectApp-LOCAL: Join Account and Parties
25/02/20 09:27:25 INFO CapstoneProjectApp-LOCAL: Apply Header and create Event
25/02/20 09:27:28 INFO CapstoneProjectApp-LOCAL: Preparing to send data to Kafka
25/02/20 09:27:28 INFO CapstoneProjectApp-LOCAL: Finished sending data to Kafka
25/02/20 09:27:28 INFO CapstoneProjectApp-LOCAL: Spark Terminate
25/02/20 20:52:29 INFO CapstoneProjectApp-LOCAL: Spark App with ID Capstone-9c51d7fe-3353-4ed8-a094-3dffc3e77ad5, Capstone Project is Running..
25/02/20 20:52:29 INFO CapstoneProjectApp-LOCAL: Spark Initialize Data and Variables for Application
25/02/20 20:52:29 INFO CapstoneProjectApp-LOCAL: Spark Reading Account Data..
25/02/20 20:52:36 INFO CapstoneProjectApp-LOCAL: Spark Reading Party Data..
25/02/20 20:52:36 INFO CapstoneProjectApp-LOCAL: Spark Reading Address Data..
25/02/20 20:52:37 INFO CapstoneProjectApp-LOCAL: Join Party Relations and Address
25/02/20 20:52:37 INFO CapstoneProjectApp-LOCAL: Join Account and Parties
25/02/20 20:52:37 INFO CapstoneProjectApp-LOCAL: Apply Header and create Event
25/02/20 20:52:39 INFO CapstoneProjectApp-LOCAL: Preparing to send data to Kafka
25/02/20 20:53:02 INFO CapstoneProjectApp-LOCAL: Finished sending data to Kafka
25/02/20 20:53:02 INFO CapstoneProjectApp-LOCAL: Spark Terminate
